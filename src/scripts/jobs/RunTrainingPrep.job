#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --gpus=1
#SBATCH --job-name=Llama
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --time=00:40:00
#SBATCH --output=job_outputs/TuningLlama/llama13b_%A.out

module purge
module load 2022
module load Anaconda3/2022.05

cd $HOME/Legommenders/

source activate dire_tokenize

# pip install easydict gdown spacy
# pip install accelerate
# pip install -i https://pypi.org/simple/ bitsandbytes
# srun python -m spacy download en_core_web_sm

srun python worker.py --embed config/embed/llama-token.yaml --model config/model/llm/llama-naml.yaml \
    --exp config/exp/llama-split.yaml --data config/data/eb-nerd.yaml --version small --llm_ver 13b \
    --hidden_size 64 --layer 0 --lora 0  --fast_eval 0 --embed_hidden_size 5120 --page_size 32