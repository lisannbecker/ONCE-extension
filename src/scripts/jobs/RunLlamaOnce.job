#!/bin/bash

#SBATCH --partition=gpu_mig
#SBATCH --gpus=1
#SBATCH --job-name=FF
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --time=02:40:00
#SBATCH --output=job_outputs/Training/ONCE/FastFormer_llama7b_ONCE%A.out

module purge
module load 2022
module load Anaconda3/2022.05

cd $HOME/sentiment-Legommenders/

source activate dire_tokenize

srun python worker.py  --data config/data/eb-nerd-once.yaml --embed config/embed/llama-token.yaml  --model config/model/llm/llama-fastformer-once.yaml --exp config/exp/tt-llm.yaml --embed_hidden_size 4096 --llm_ver 7b --layer 31 --version small --lr 0.0001 --item_lr 0.00001 --batch_size 32 --acc_batch 2 --epoch_batch -4  